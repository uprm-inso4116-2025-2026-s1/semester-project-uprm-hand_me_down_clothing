=== Generative AI Use Disclosure Statement

Across all teams and management roles in the Hand-Me-Down project, Generative AI tools were used intentionally and transparently. The primary tools used throughout the project were ChatGPT (versions 4, 5, and 5.1 in both free and paid tiers) and GitHub Copilot through the GitHub Student Pack. ChatGPT was used for research, documentation drafting, debugging explanations, and architectural reasoning, while GitHub Copilot acted as an inline coding assistant within Visual Studio Code, offering syntax suggestions and small refactoring improvements.
AI supported teams at multiple stages of development. During early research, AI helped compare technologies (e.g., Supabase vs. Firebase), understand new frameworks such as React, Leaflet, and TypeScript, and clarify concepts like authentication flows, coordinate math, map clustering, and RLS logic. During implementation, AI assisted in debugging issues like map rendering lag or OAuth misconfigurations, clarifying API behavior, and generating draft code snippets that were later refined manually. In the documentation phase, AI was used to refine clarity, unify writing styles, check grammar, generate AsciiDoc formatting, and cross-reference milestone guidelines.
Project Managers also used AI meaningfully. AI helped them create structured templates for Scrum preparation, ensuring meetings followed a clear and consistent agenda. Managers relied on AI to clarify doubts about the codebase, resolve logistical or technical ambiguities, streamline communication, and maintain alignment across all teams. This allowed the management group to make more informed decisions and support the project with greater efficiency.
Despite these uses, all core contributions, including architecture, final code logic, domain modeling, UI design, and implementation decisions, were produced by team members themselves. AI-assisted content was always reviewed, corrected, adapted, or rewritten to meet project architecture and academic guidelines. Human reasoning guided all key decisions.
To verify AI-generated content, teams cross-checked official documentation (Supabase, React, Leaflet), performed manual debugging and testing, validated behavior within the application, and compared outputs to milestone guidelines and the professorâ€™s feedback. When AI produced outdated or incorrect suggestions, such as deprecated Leaflet clustering options, incorrect OAuth redirects, or fabricated documentation sections, teams resolved them through testing and authoritative sources.
Overall, the use of AI enhanced productivity, clarified complex concepts, and improved collaboration across teams and managers. It accelerated brainstorming and documentation tasks while reinforcing the need for critical thinking and verification. AI functioned as a supportive tool, not a replacement for human expertise, strengthening both technical understanding and project coordination.
